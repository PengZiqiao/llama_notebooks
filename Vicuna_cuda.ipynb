{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd '/content'\n",
        "!git clone 'https://github.com/oobabooga/text-generation-webui.git'\n",
        "\n",
        "%cd '/content/text-generation-webui'\n",
        "!pip install -r requirements.txt\n",
        "!pip install xformers"
      ],
      "metadata": {
        "id": "dlee9xP0h8cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ftsx1KEoXPw0"
      },
      "outputs": [],
      "source": [
        "%mkdir /content/text-generation-webui/repositories/\n",
        "%cd /content/text-generation-webui/repositories/\n",
        "!git clone 'https://github.com/oobabooga/GPTQ-for-LLaMa.git' -b cuda\n",
        "\n",
        "%cd '/content/text-generation-webui/repositories/GPTQ-for-LLaMa'\n",
        "!pip install -r requirements.txt\n",
        "!python setup_cuda.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/text-generation-webui'\n",
        "model_download = \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\" #@param {type:\"string\"}\n",
        "!python download-model.py {model_download}"
      ],
      "metadata": {
        "id": "PhSYxJ9Yd2mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = []\n",
        "\n",
        "share = True #@param {type:\"boolean\"}\n",
        "if share:\n",
        "  params.append('--share')\n",
        "\n",
        "auto_devices = True #@param {type:\"boolean\"}\n",
        "if auto_devices:\n",
        "  params.append('--auto-devices')\n",
        "\n",
        "xformers = True #@param {type:\"boolean\"}\n",
        "if xformers:\n",
        "  params.append('--xformers')\n",
        "\n",
        "verbose = True #@param {type:\"boolean\"}\n",
        "if verbose:\n",
        "  params.append('--verbose')\n",
        "\n",
        "chat = True #@param {type:\"boolean\"}\n",
        "if chat:\n",
        "  params.append('--chat')\n",
        "\n",
        "wbits = 4 #@param {type:\"string\"}\n",
        "params.append(f'--wbits {wbits}')\n",
        "\n",
        "groupsize = 128 #@param {type:\"string\"}\n",
        "params.append(f'--groupsize {groupsize}')\n",
        "\n",
        "%cd '/content/text-generation-webui'\n",
        "!python server.py \\\n",
        "--model-dir '/content/text-generation-webui/models' \\\n",
        "{' '.join(params)}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NwUW6s0xatKW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}